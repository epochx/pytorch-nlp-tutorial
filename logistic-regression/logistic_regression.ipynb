{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yGq73z07jiXU"
   },
   "source": [
    "# Google Colaboratory Specs:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f5utee74kEuE"
   },
   "source": [
    "- Check that we have enabled GPU capabilities, and inspect GPU specs:\n",
    "  -  Edit > Notebook settings or Runtime>Change runtime type and select GPU as Hardware accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3282,
     "status": "ok",
     "timestamp": 1524454398826,
     "user": {
      "displayName": "Edison",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "103264836563542052392"
     },
     "user_tz": -720
    },
    "id": "aD8-T-dljh_Q",
    "outputId": "454dd5ce-680e-464f-d768-a15800e7c0af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 23 03:33:17 2018       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 384.111                Driver Version: 384.111                   |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   35C    P8    30W / 149W |      0MiB / 11439MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "! /opt/bin/nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "md4bWX-akT2O"
   },
   "source": [
    "- Check CPU, RAM, disk-quota and storing capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 786
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1882,
     "status": "ok",
     "timestamp": 1524454671816,
     "user": {
      "displayName": "Edison",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "103264836563542052392"
     },
     "user_tz": -720
    },
    "id": "TafzfYe6jz5e",
    "outputId": "e061674d-e467-4b72-b8e0-14432625b640"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MemTotal:       13341832 kB\r\n",
      "MemFree:         1849328 kB\r\n",
      "MemAvailable:   12443920 kB\r\n",
      "Buffers:          125464 kB\r\n",
      "Cached:         10388640 kB\r\n",
      "SwapCached:            0 kB\r\n",
      "Active:          1913656 kB\r\n",
      "Inactive:        8882020 kB\r\n",
      "Active(anon):     352400 kB\r\n",
      "Inactive(anon):   183064 kB\r\n",
      "Active(file):    1561256 kB\r\n",
      "Inactive(file):  8698956 kB\r\n",
      "Unevictable:           0 kB\r\n",
      "Mlocked:               0 kB\r\n",
      "SwapTotal:             0 kB\r\n",
      "SwapFree:              0 kB\r\n",
      "Dirty:               328 kB\r\n",
      "Writeback:             0 kB\r\n",
      "AnonPages:        281648 kB\r\n",
      "Mapped:           126320 kB\r\n",
      "Shmem:            253900 kB\r\n",
      "Slab:             614164 kB\r\n",
      "SReclaimable:     587796 kB\r\n",
      "SUnreclaim:        26368 kB\r\n",
      "KernelStack:        3056 kB\r\n",
      "PageTables:         4116 kB\r\n",
      "NFS_Unstable:          0 kB\r\n",
      "Bounce:                0 kB\r\n",
      "WritebackTmp:          0 kB\r\n",
      "CommitLimit:     6670916 kB\r\n",
      "Committed_AS:    1467484 kB\r\n",
      "VmallocTotal:   34359738367 kB\r\n",
      "VmallocUsed:           0 kB\r\n",
      "VmallocChunk:          0 kB\r\n",
      "AnonHugePages:         0 kB\r\n",
      "HugePages_Total:       0\r\n",
      "HugePages_Free:        0\r\n",
      "HugePages_Rsvd:        0\r\n",
      "HugePages_Surp:        0\r\n",
      "Hugepagesize:       2048 kB\r\n",
      "DirectMap4k:       81868 kB\r\n",
      "DirectMap2M:     3063808 kB\r\n",
      "DirectMap1G:    12582912 kB\r\n"
     ]
    }
   ],
   "source": [
    "!cat /proc/meminfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1002
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2132,
     "status": "ok",
     "timestamp": 1524454684892,
     "user": {
      "displayName": "Edison",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "103264836563542052392"
     },
     "user_tz": -720
    },
    "id": "HUQJ3JPVlFZ4",
    "outputId": "d5a3577c-539e-421a-dd88-acbb19af7ee1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processor\t: 0\r\n",
      "vendor_id\t: GenuineIntel\r\n",
      "cpu family\t: 6\r\n",
      "model\t\t: 63\r\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\r\n",
      "stepping\t: 0\r\n",
      "microcode\t: 0x1\r\n",
      "cpu MHz\t\t: 2300.000\r\n",
      "cache size\t: 46080 KB\r\n",
      "physical id\t: 0\r\n",
      "siblings\t: 2\r\n",
      "core id\t\t: 0\r\n",
      "cpu cores\t: 1\r\n",
      "apicid\t\t: 0\r\n",
      "initial apicid\t: 0\r\n",
      "fpu\t\t: yes\r\n",
      "fpu_exception\t: yes\r\n",
      "cpuid level\t: 13\r\n",
      "wp\t\t: yes\r\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc eagerfpu pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm kaiser fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms xsaveopt\r\n",
      "bugs\t\t:\r\n",
      "bogomips\t: 4600.00\r\n",
      "clflush size\t: 64\r\n",
      "cache_alignment\t: 64\r\n",
      "address sizes\t: 46 bits physical, 48 bits virtual\r\n",
      "power management:\r\n",
      "\r\n",
      "processor\t: 1\r\n",
      "vendor_id\t: GenuineIntel\r\n",
      "cpu family\t: 6\r\n",
      "model\t\t: 63\r\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\r\n",
      "stepping\t: 0\r\n",
      "microcode\t: 0x1\r\n",
      "cpu MHz\t\t: 2300.000\r\n",
      "cache size\t: 46080 KB\r\n",
      "physical id\t: 0\r\n",
      "siblings\t: 2\r\n",
      "core id\t\t: 0\r\n",
      "cpu cores\t: 1\r\n",
      "apicid\t\t: 1\r\n",
      "initial apicid\t: 1\r\n",
      "fpu\t\t: yes\r\n",
      "fpu_exception\t: yes\r\n",
      "cpuid level\t: 13\r\n",
      "wp\t\t: yes\r\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc eagerfpu pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm kaiser fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms xsaveopt\r\n",
      "bugs\t\t:\r\n",
      "bogomips\t: 4600.00\r\n",
      "clflush size\t: 64\r\n",
      "cache_alignment\t: 64\r\n",
      "address sizes\t: 46 bits physical, 48 bits virtual\r\n",
      "power management:\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! cat /proc/cpuinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1850,
     "status": "ok",
     "timestamp": 1524454690136,
     "user": {
      "displayName": "Edison",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "103264836563542052392"
     },
     "user_tz": -720
    },
    "id": "sUmReSEVlHeU",
    "outputId": "5c6c5930-1aa5-42bd-e1ae-e655ea56d48c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\r\n",
      "overlay         359G  5.9G  335G   2% /\r\n",
      "tmpfs           6.4G     0  6.4G   0% /dev\r\n",
      "tmpfs           6.4G     0  6.4G   0% /sys/fs/cgroup\r\n",
      "/dev/root       1.2G  537M  684M  44% /opt/bin\r\n",
      "tmpfs           6.4G  248M  6.2G   4% /usr/lib64-nvidia\r\n",
      "/dev/sda1       365G  7.3G  358G   2% /etc/hosts\r\n",
      "shm              64M     0   64M   0% /dev/shm\r\n",
      "tmpfs           6.4G     0  6.4G   0% /sys/firmware\r\n"
     ]
    }
   ],
   "source": [
    "! df -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FVCT8Pi4jZUq"
   },
   "source": [
    "## Installing pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "BvdNJyqG_oQ4"
   },
   "outputs": [],
   "source": [
    "# http://pytorch.org/\n",
    "from os import path\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "\n",
    "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dFc19f5WH4og"
   },
   "source": [
    "# Logistic Regression on MNIST with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "1X8Dv3oEiIL7"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kNiTAHZalfce"
   },
   "source": [
    "## Brief Pytorch API summary\n",
    "- The interface is very similar to numpy, operations are based on Tensors, which are roughly similar to numpy ndarrays.\n",
    "- Most operators return a new tensor after computing, but some can be applied 'in-place', meaning that the operations are performed over the object. These functions generally have an underscore in their name.   \n",
    "- Simple operations, such as addition and product, are overloaded into Python syntax.\n",
    "- More complex functions are accessible using the API, having [pytorch.org/docs](http://pytorch.org/docs) in the background when developing is always recommended. Also keep in mind that Pytorch is under active development and the API is subject to change frequently; always make sure that the version of the docs you're reading is the same as the one you have installed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 956,
     "status": "ok",
     "timestamp": 1524455182840,
     "user": {
      "displayName": "Edison",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "103264836563542052392"
     },
     "user_tz": -720
    },
    "id": "XZntaQ38iP6Q",
    "outputId": "e11f1447-f64f-4c4c-9e7b-0eebc2ded676"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1  2\n",
      " 3  4\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,2], [3,4]])\n",
    "print(x)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1028,
     "status": "ok",
     "timestamp": 1524455213562,
     "user": {
      "displayName": "Edison",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "103264836563542052392"
     },
     "user_tz": -720
    },
    "id": "RxPh4KwMmoaA",
    "outputId": "e8e84eca-5fab-4a98-bbd6-cf009a6fddb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 3  4\n",
      " 5  6\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "\n",
      " 3  4\n",
      " 5  6\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(x+1)\n",
    "x.add_(1)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lcSw_EtYp6CK"
   },
   "source": [
    "- Tensors can be transposed, reshaped and manipulated according to our needs. This is mainly accomplished using the `transpose()` and `view()` functions. \n",
    "- These reshapings are generally needed when we use the Pytorch API for neural nets, which makes certain assumptions about the shape of the input data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 856,
     "status": "ok",
     "timestamp": 1524456097274,
     "user": {
      "displayName": "Edison",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "103264836563542052392"
     },
     "user_tz": -720
    },
    "id": "bUunRQMQp1VK",
    "outputId": "700d0914-63c4-494d-833c-23ef8b21f3f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 3  4\n",
      " 5  6\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "\n",
      " 3  5\n",
      " 4  6\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "\n",
      " 3\n",
      " 4\n",
      " 5\n",
      " 6\n",
      "[torch.FloatTensor of size 4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(x.transpose(0, 1))\n",
    "print(x.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 764,
     "status": "ok",
     "timestamp": 1524456873124,
     "user": {
      "displayName": "Edison",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "103264836563542052392"
     },
     "user_tz": -720
    },
    "id": "P66Do8y0rxp4",
    "outputId": "ceaabbb6-5719-4ef3-d5bb-f3c271a9cde5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 2\n",
      " 3\n",
      " 4\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "a = Variable(torch.FloatTensor([2, 3, 4]))\n",
    "print(a)\n",
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hQ2kYy9Lrkn4"
   },
   "source": [
    "- the `autograd.Variable` object represents one node in the computational graph, meaning that all operations we perform over the object will be recorded. Thus we can later go through the graph for backpropagation. \n",
    "- Every `Variable` object contains a `.data` attribute holding the tensor which contains its current value, as well as a `.grad` attribute holding the current value of the gradient. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "loaYTwer8enE"
   },
   "source": [
    "- By simply calling the `.cuda()` function on any Tensor, Variable or Module, we can easily move our objects to the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 906,
     "status": "ok",
     "timestamp": 1524460817004,
     "user": {
      "displayName": "Edison",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "103264836563542052392"
     },
     "user_tz": -720
    },
    "id": "4WU6okWI8d82",
    "outputId": "7c171240-df28-4a08-be13-293ee8542e48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 3  4\n",
       " 5  6\n",
       "[torch.cuda.FloatTensor of size 2x2 (GPU 0)]"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aHjeu_ewtiFG"
   },
   "source": [
    "- Nodes in the graph should implement both the `forward()` and `backward()` functions, making them suitable to use when training models using backprop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7naog-jplwhY"
   },
   "source": [
    "## Loading and understanding the MNIST dataset\n",
    "- The torchvision package offers us access to some of the most popular datasets for image classification, let's load the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29550,
     "status": "ok",
     "timestamp": 1524456175624,
     "user": {
      "displayName": "Edison",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "103264836563542052392"
     },
     "user_tz": -720
    },
    "id": "UF_uduGFk_jy",
    "outputId": "d6cd2d9c-79e2-4f3b-a5bc-5cfc31ffd73e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset (images and labels)\n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 804,
     "status": "ok",
     "timestamp": 1524456290680,
     "user": {
      "displayName": "Edison",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "103264836563542052392"
     },
     "user_tz": -720
    },
    "id": "9xYT2LV6q3TY",
    "outputId": "41610b0f-d75d-47e4-ffa0-5ea0a5873c98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yQ0aOFFQuG_4"
   },
   "source": [
    "- MINST is a dataset for image classification, with 28x28 pixel images of hadwritten numbers from 0 to 9, every image is labeled with the digit it contains.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 836,
     "status": "ok",
     "timestamp": 1524456351198,
     "user": {
      "displayName": "Edison",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "103264836563542052392"
     },
     "user_tz": -720
    },
    "id": "sTT-xYEvrC6c",
    "outputId": "2bcbbbf4-f7b3-47d4-8718-b41158c43dcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.FloatTensor'> torch.Size([1, 28, 28])\n",
      "<class 'int'> 3\n"
     ]
    }
   ],
   "source": [
    "image, label = train_dataset[10]\n",
    "print(type(image), image.size()) \n",
    "print(type(label), label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cgiqObDYunKC"
   },
   "source": [
    "- Let's visualize a random image in the training dataset, we first need to give it the adequate shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 918,
     "status": "ok",
     "timestamp": 1524457226944,
     "user": {
      "displayName": "Edison",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "103264836563542052392"
     },
     "user_tz": -720
    },
    "id": "tA3As_cIq4C4",
    "outputId": "fe3e0784-5cca-4ff5-90d3-54410ef8ea60"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFZCAYAAAARqQ0OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb048855cf8>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = image.view(28, 28)\n",
    "plt.title('Label is {label}'.format(label=label))\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pxBKH8iju6JY"
   },
   "source": [
    "## Logistic Regression\n",
    "- Let's start by setting the hyper parameters of our yet-to-define model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3DCkTrsnk7Qv"
   },
   "outputs": [],
   "source": [
    "# hyper-parameters \n",
    "input_size = 784 # 28*28\n",
    "num_classes = 10 # ten digits\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "gpu = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cfEnY3P7whsg"
   },
   "source": [
    "- Our next step is to define the model. To do so, we can extend the `torch.nn.Module` class, which will alow us to reuse some of the internal structure that Pytorch has prepared. \n",
    "- We need to define the `__init__()` and `forward()` functions which will take care of initializing the parameters of our model and computing the outputs given an example, respectively.\n",
    "- As long as we use Pytorch objects and operations, we do not have to define the `backward()` function ourselves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hJyNgHq9lEkC"
   },
   "outputs": [],
   "source": [
    "# model\n",
    "class LogisticRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "0PxUTcuZy3Uo"
   },
   "outputs": [],
   "source": [
    "nn.Linear?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 988,
     "status": "ok",
     "timestamp": 1524458553044,
     "user": {
      "displayName": "Edison",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "103264836563542052392"
     },
     "user_tz": -720
    },
    "id": "A7zmXqlezj4-",
    "outputId": "62e54157-87d9-4bed-b499-8478a63c67f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "1.00000e-02 *\n",
      " 0.7272 -1.1373 -3.2398  ...   1.4452 -0.4124  0.3366\n",
      "-0.7966  2.2443  3.4614  ...  -0.9685  1.9105 -2.5403\n",
      "-2.0471  3.0039 -2.1513  ...  -0.1475  1.6174 -2.3009\n",
      "          ...             â‹±             ...          \n",
      "-1.1068 -0.3257  0.7907  ...  -2.5069  2.8124 -0.3861\n",
      "-1.5549 -0.0535  2.1785  ...   2.8439 -1.4620 -3.2285\n",
      " 2.4033  2.8019 -3.5307  ...  -1.8888  2.1390  0.7014\n",
      "[torch.cuda.FloatTensor of size 10x784 (GPU 0)]\n",
      "\n",
      "Parameter containing:\n",
      "1.00000e-02 *\n",
      "  3.0359\n",
      " -0.4516\n",
      " -3.3617\n",
      " -3.5198\n",
      " -3.2848\n",
      " -0.5634\n",
      " -0.5879\n",
      "  1.5056\n",
      "  0.2142\n",
      " -0.4263\n",
      "[torch.cuda.FloatTensor of size 10 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.linear.weight)\n",
    "print(model.linear.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5fkEnHaXxrLS"
   },
   "source": [
    "- `nn.Linear()` offers us a shortcut for defining single layer neural networks of the form $y = Ax  + b$ , following all the good practices of parameter initialization.\n",
    "- Note that the API for `nn.Linear()` expects a tensor of size `(N_examples, n_features)`, where generally `N_features` indicates that we could pass a *mini-batch* of examples to the model at the same time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nGSvbyci89So"
   },
   "source": [
    "- Next, let's instantiate our model, set the adequate loss function for our problem and use stochastic gradient descent as our training algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3418,
     "status": "ok",
     "timestamp": 1524458146494,
     "user": {
      "displayName": "Edison",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "103264836563542052392"
     },
     "user_tz": -720
    },
    "id": "BzihvrXExp0k",
    "outputId": "329654ab-f108-408e-ed64-9dfcaa9f1c82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(\n",
      "  (linear): Linear(in_features=784, out_features=10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(input_size, num_classes)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "if gpu:\n",
    "  model.cuda()\n",
    "  \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "28jM5tZS8ri8"
   },
   "outputs": [],
   "source": [
    "nn.CrossEntropyLoss?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mTUlMDeM8oxA"
   },
   "source": [
    "- `nn.CrossEntropy()` is a Pytorch efficient implementation of the cross entropy, which is the loss funtion of preference for multi-class classification. Note that it expects two inputs: a tensor of size `(N_examples, N_classes)` containing the logits (non-normalized probabilities) for each class on each instance, and the hard label for the batch of shape `(N_examples)`.\n",
    "- The function `model.parameters()` returns an iterable over the paramerets of the model, which are simply tensors wrapped in the special `nn.Parameter()` object.\n",
    "- The `torch.optim.SGD()` object receives our model parameters and the learning rate, and is in charge of simply updating these using the gradients and the update rule that we are familiar with: $\\theta \\leftarrow \\theta - \\alpha * \\nabla \\theta$, where $\\alpha$ is our learning rate and $\\theta$ symbolizes our model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MOWbCO_Y0JA0"
   },
   "source": [
    "- Let's prepare our data for training, we can use torch.utils for doing so. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "RDQWPyWnk_hd"
   },
   "outputs": [],
   "source": [
    "# dataset loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8D14xlrx67no"
   },
   "source": [
    "- Now we can train our model using all the components we've built above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20696,
     "status": "ok",
     "timestamp": 1521426882090,
     "user": {
      "displayName": "Edison",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "103264836563542052392"
     },
     "user_tz": -780
    },
    "id": "eo8LwG7-lISC",
    "outputId": "c2d3705a-f54d-4031-c2af-59e5dfc2c8e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/5], Step: [100/600], Loss: 2.1771\n",
      "Epoch: [1/5], Step: [200/600], Loss: 2.0870\n",
      "Epoch: [1/5], Step: [300/600], Loss: 2.0491\n",
      "Epoch: [1/5], Step: [400/600], Loss: 1.9460\n",
      "Epoch: [1/5], Step: [500/600], Loss: 1.8677\n",
      "Epoch: [1/5], Step: [600/600], Loss: 1.8068\n",
      "Epoch: [2/5], Step: [100/600], Loss: 1.7278\n",
      "Epoch: [2/5], Step: [200/600], Loss: 1.6587\n",
      "Epoch: [2/5], Step: [300/600], Loss: 1.6548\n",
      "Epoch: [2/5], Step: [400/600], Loss: 1.5598\n",
      "Epoch: [2/5], Step: [500/600], Loss: 1.4971\n",
      "Epoch: [2/5], Step: [600/600], Loss: 1.4906\n",
      "Epoch: [3/5], Step: [100/600], Loss: 1.3387\n",
      "Epoch: [3/5], Step: [200/600], Loss: 1.3933\n",
      "Epoch: [3/5], Step: [300/600], Loss: 1.4217\n",
      "Epoch: [3/5], Step: [400/600], Loss: 1.3266\n",
      "Epoch: [3/5], Step: [500/600], Loss: 1.2850\n",
      "Epoch: [3/5], Step: [600/600], Loss: 1.2596\n",
      "Epoch: [4/5], Step: [100/600], Loss: 1.2900\n",
      "Epoch: [4/5], Step: [200/600], Loss: 1.1672\n",
      "Epoch: [4/5], Step: [300/600], Loss: 1.1423\n",
      "Epoch: [4/5], Step: [400/600], Loss: 1.1485\n",
      "Epoch: [4/5], Step: [500/600], Loss: 1.1152\n",
      "Epoch: [4/5], Step: [600/600], Loss: 1.0613\n",
      "Epoch: [5/5], Step: [100/600], Loss: 1.1713\n",
      "Epoch: [5/5], Step: [200/600], Loss: 0.9474\n",
      "Epoch: [5/5], Step: [300/600], Loss: 0.9563\n",
      "Epoch: [5/5], Step: [400/600], Loss: 1.0296\n",
      "Epoch: [5/5], Step: [500/600], Loss: 1.0534\n",
      "Epoch: [5/5], Step: [600/600], Loss: 1.0639\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        # we make our data a part of the graph\n",
    "        # wrapping it in the Variable object\n",
    "        # and reshape our data to have the adequate shape\n",
    "        images = Variable(images.view(-1, 28*28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # we move our data to the GPU if necessary\n",
    "        if gpu:\n",
    "          images = images.cuda()\n",
    "          labels = labels.cuda()\n",
    "        \n",
    "        # make sure our gradients are 0 to start\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # call forward() to compute the \n",
    "        # outputs of the model given our examples\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # compute the loss and call backward()\n",
    "        # to compute gradients\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # apply our learning rule using the gradients\n",
    "        # stored in the parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch: [%d/%d], Step: [%d/%d], Loss: %.4f' \n",
    "                   % (epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1286,
     "status": "ok",
     "timestamp": 1521426927844,
     "user": {
      "displayName": "Edison",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "103264836563542052392"
     },
     "user_tz": -780
    },
    "id": "3CYyPmnHlIVG",
    "outputId": "4d9764ac-bd67-4711-f77b-89b6e3a250f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 10000 test images: 82 %\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    if gpu:\n",
    "      images = images.cuda()\n",
    "      labels = labels.cuda()\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "    \n",
    "print('Accuracy of the model on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "kNQ8Wyl1lIPQ"
   },
   "outputs": [],
   "source": [
    "# save the trained model (a.k.a model parameters)\n",
    "torch.save(model.state_dict(), 'model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Kdy1Iuhp4ra"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "pytorch_logistic_regression.ipynb",
   "provenance": [
    {
     "file_id": "1hDtN9qiKQyPjPyjYDZbelcgQ0I28zgOz",
     "timestamp": 1516675262030
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
